# Production Docker Compose configuration
version: '3.8'

services:
  redis:
    image: redis:7-alpine
    restart: unless-stopped
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 3

  backend:
    build: ./backend
    restart: unless-stopped
    ports:
      - "8000:8000"
    env_file:
      - .env
    environment:
      - REDIS_URL=redis://redis:6379/0
      - DATABASE_URL=sqlite:///./data/pkm.db
      - CHROMA_DB_PATH=./data/chroma_db
      - RAG_STORAGE_DIR=./data/rag_storage
      - UPLOAD_DIR=./data/uploads
      - PROCESSED_DIR=./data/processed
      - MAX_FILE_SIZE=104857600
      - DEBUG=false
      - LOG_LEVEL=INFO
      - MINERU_DEVICE=cpu
      - MINERU_BACKEND=pipeline
      - MINERU_LANG=en
      # OpenAI Configuration (from .env file)
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OPENAI_BASE_URL=${OPENAI_BASE_URL:-https://api.openai.com/v1}
      - LLM_MODEL=${LLM_MODEL:-gpt-4o-mini}
      - VISION_MODEL=${VISION_MODEL:-gpt-4o}
      - EMBEDDING_MODEL=${EMBEDDING_MODEL:-text-embedding-3-large}
    volumes:
      - backend_data:/app/data
      - ./data:/app/data
    depends_on:
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "python", "-c", "import requests; requests.get('http://localhost:8000/health', timeout=5)"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  celery:
    build: ./backend
    restart: unless-stopped
    command: celery -A app.core.celery_app worker --loglevel=info --concurrency=2
    env_file:
      - .env
    environment:
      - REDIS_URL=redis://redis:6379/0
      - DATABASE_URL=sqlite:///./data/pkm.db
      - CHROMA_DB_PATH=./data/chroma_db
      - RAG_STORAGE_DIR=./data/rag_storage
      - UPLOAD_DIR=./data/uploads
      - PROCESSED_DIR=./data/processed
      - MAX_FILE_SIZE=104857600
      - DEBUG=false
      - LOG_LEVEL=INFO
      - MINERU_DEVICE=cpu
      - MINERU_BACKEND=pipeline
      - MINERU_LANG=en
      # OpenAI Configuration (from .env file)
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OPENAI_BASE_URL=${OPENAI_BASE_URL:-https://api.openai.com/v1}
      - LLM_MODEL=${LLM_MODEL:-gpt-4o-mini}
      - VISION_MODEL=${VISION_MODEL:-gpt-4o}
      - EMBEDDING_MODEL=${EMBEDDING_MODEL:-text-embedding-3-large}
    volumes:
      - backend_data:/app/data
      - ./data:/app/data
    depends_on:
      redis:
        condition: service_healthy
      backend:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "celery", "-A", "app.core.celery_app", "inspect", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  frontend:
    build: ./frontend
    restart: unless-stopped
    ports:
      - "80:80"
    depends_on:
      backend:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:80"]
      interval: 30s
      timeout: 10s
      retries: 3

volumes:
  redis_data:
  backend_data: